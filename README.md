# HPLL Tutorials
`HPLL`(`High Performance Low Latency`)，主要用`C++`写了一些demo来理解相关原理。

---

## mutex和atomic
### 基本概念
#### mutex
互斥锁（`Mutex`）是一种同步原语，通过锁定和解锁机制来保护临界区（`critical section`），确保同一时刻只有一个线程能访问被保护的代码段或数据。它属于较高级别的同步工具。
#### atomic
原子类型通过硬件支持的原子操作（如`CAS`或`fetch-add`）直接对单个变量进行线程安全的操作，无需显式锁定。它是低级别的同步工具，专注于单个对象的操作。

### 功能与作用
#### mutex
* 保护范围：可以保护任意大小的代码块（临界区），包括多个变量或复杂逻辑。
* 同步方式：通过加锁（`lock()`）和解锁（`unlock()`）显式控制线程访问。
  ```c++
  std::mutex mtx;
  int counter = 0;
    
  void increment() {
    mtx.lock();
    counter++; // 保护整个操作
    mtx.unlock();
  }
  ```
#### atomic
* 保护范围：仅限于单个变量的原子操作（如读、写、加减）。
* 同步方式：隐式保证操作的原子性，无需手动加锁
  ```c++
  std::atomic<int> counter(0);

  void increment() {
    counter++; // 原子操作，无需锁
  }
  ```
### 性能
#### mutex
* 开销较高：涉及操作系统级别的线程调度和上下文切换。如果锁竞争激烈，线程可能被阻塞，性能下降明显。
* 适合复杂操作，但不适合高频、简单的数据访问。
#### atomic
* 开销较低：依赖硬件级别的原子指令（如`LOCK`前缀指令），通常比锁快，尤其在低竞争场景下。
* 在高竞争场景下，可能因缓存一致性协议（如`MESI`）导致性能下降，但仍比锁轻量。
### 使用场景
#### mutex
* 适合需要保护多个变量或复杂逻辑的场景。
* 示例：更新一个对象的多个字段，或执行需要多步操作的业务逻辑。
  ```c++
  std::mutex mtx;
  std::vector<int> vec;

  void add(int value) {
    std::lock_guard<std::mutex> guard(mtx);
    vec.push_back(value); // 保护整个操作
  }
  ```
#### atomic
* 适合简单的单变量操作，如计数器、标志位或指针更新。
* 示例：线程安全的计数器或状态标志。
  ```c++
  std::atomic<int> flag(0);
  void set_flag() {
    flag.store(1); // 原子写
  }
  ```
### 灵活性
#### mutex
* 更灵活：可以与条件变量（`std::condition_variable`）配合使用，支持复杂的线程同步需求（如等待/通知模式）。
* 支持范围锁（如`std::lock_guard`或`std::unique_lock`），使用更安全。
#### atomic
* 灵活性有限：仅支持预定义的原子操作（如`load、store`,`fetch_add`），无法保护多步逻辑。
* 可通过内存顺序（`memory order`）微调性能和一致性，但使用复杂。

### 易用性与安全性
#### mutex
* 易用性：需要手动管理锁的加锁和解锁，容易出错（如忘记解锁导致死锁）。
* 安全性：配合`RAII`工具（如`std::lock_guard`）可以减少错误。
#### atomic
* 易用性：无需显式锁管理，使用简单。
* 安全性：天然线程安全，但需要理解内存顺序的含义，否则可能引入微妙的同步问题。

### 局限性
#### mutex
* 不能用于单变量的高频操作，因为锁的开销太大。
* 多线程竞争激烈时，性能瓶颈明显。
#### atomic
* 仅限单变量操作，无法保护多变量或复杂逻辑。
* 不支持所有类型（如复杂的自定义类可能无法直接原子化）。

### 总结

| 特性   | 	mutex        | 	atomic       |
|------|---------------|---------------|
| 保护范围 | 	任意代码块        | 	单变量          |
| 性能   | 	较高开销（锁竞争时阻塞） | 	较低开销（硬件原子指令） |
| 适用场景 | 	复杂逻辑、多变量     | 	简单变量操作（如计数器） |
| 灵活性  | 	高（支持条件变量等 ）  | 	低（仅限原子操作）    |
| 易用性  | 	需手动管理锁       | 	简单，无需锁管理     |

### 建议
* 如果只需要操作单个变量（如计数器或标志位），优先使用`std::atomic`，因为它更高效。
* 如果需要保护多变量或复杂逻辑，使用`std::mutex`，因为它更通用。
* 在性能敏感的无锁编程中，`std::atomic`是首选，但需要仔细设计内存顺序。

---

## const和constexpr
### 相同点
* 限制修改
  * 两者都可以用来声明不可修改的值。
* 提高代码可读性
  * 它们都能表明变量或函数的意图，表示某些值在程序运行期间保持不变。
* 作用于变量
  * 都可以用来定义常量变量，避免意外修改。

### 不同点
* 定义时间与初始化
  * `const`
    * 表示变量的值在初始化后不可修改，但初始化可以在运行时发生。
    * 不要求编译时常量，可以依赖运行时数据。
  * `consexpr`
    * 表示变量或表达式的值必须在编译时可计算，是一种编译时常量。
    * 初始化必须是常量表达式（`constant expression`）。
* 适用范围
  * `const`
    * 可用于变量、指针、引用、类成员函数等，限制其修改。
  * `constexpr`
    * 不仅限于变量，还可用于函数和构造函数，要求它们在编译时可求值。
* 性能与优化
  * `const`
    * 不保证编译时计算，编译器可能将其优化，但不是强制要求。
  * `constexpr`
    * 强制要求编译时计算，适用于需要常量的地方（如数组大小、模板参数）。
* 灵活性与限制
  * `const`
    * 更灵活，可以用在运行时场景，不要求编译时可知。
  * `constexpr`
    * 更严格，必须在编译时完全确定值，不能依赖运行时数据。
* 函数中的使用
  * `const`
    * 用于成员函数，表示不修改对象状态。
  * `consexpr`
    * 用于定义能在编译时执行的函数，返回值必须是常量表达式。
* `constexpr`的扩展
  * 在`C++11`中，`constexpr`仅支持简单函数和变量。
  * 在`C++14`和`C++17`中，`constexpr`支持更复杂的逻辑（如条件语句、循环），甚至可以在编译时执行完整算法。

### 总结

| 特性    | 	const	      | constexpr     |
|-------|--------------|---------------|
| 定义时间  | 	运行时或编译时	    | 必须在编译时确定      |
| 适用范围	 | 变量、指针、成员函数等	 | 变量、函数、构造函数等   |
| 初始化要求 | 	可在运行时初始化    | 	必须在编译时初始化    |
| 性能优化	 | 不保证编译时计算     | 	保证编译时计算，优化性能 |
| 使用场景  | 	表示不可变性      | 	表示编译时常量或计算   |

### 建议
* 如果只需要不可变性，用`const`
* 如果需要编译时常量或优化，用`constexpr`

### 使用 constexpr 相比 const 的优势
#### 编译时计算，性能提升
* `constexpr`的优势
  * `constexpr`强制要求在编译时计算其值，生成的代码中不会涉及运行时开销。这可以减少程序运行时的计算负担，尤其在性能敏感的场景下（如嵌入式系统或高性能计算）。
* 对比const
  * `const`变量的值可以在运行时初始化，编译器可能优化，但不保证在编译时完成计算，某些情况下仍需运行时操作。
* 示例
  ```c++
  const int size = 10 * 2;              // 可能在运行时计算
  constexpr int optimizedSize = 10 * 2; // 编译时计算为 20
  int arr[optimizedSize];               // OK，编译时常量可用作数组大小
  ```
  * 使用`constexpr`的`optimizedSize`在编译时直接替换为`20`，生成的汇编代码更高效。

#### 支持编译时常量场景
* `constexpr`的优势：
  * 某些语言特性（如数组大小、模板参数、枚举值初始化等）要求编译时常量，只有`constexpr`能满足这些需求。
* 对比 const：
  * `const`定义的常量不一定是编译时常量（如果依赖运行时数据），因此无法用于这些场景。
* 示例
  ```c++
  const int n = 5;         // 运行时或编译时，取决于上下文
  // int arr[n];           // 错误，n不是编译时常量
  constexpr int m = 5;     // 编译时常量
  int arr[m];              // OK，可用作数组大小
  ```
  * 优势：`constexpr`扩展了常量在编译时语义的使用范围。

#### 支持编译时函数计算
* `constexpr`的优势
  * `constexpr`可以修饰函数，使其在编译时执行复杂逻辑，返回编译时常量。这不仅优化性能，还能将计算提前到编译阶段。
* 对比`const`
  * `const`不能修饰函数，无法实现类似的编译时计算。
* 示例
  ```c++
  constexpr int factorial(int n) {
    return (n <= 1) ? 1 : n * factorial(n - 1);
  }
  constexpr int result = factorial(5); // 编译时计算为 120
  int arr[result];                     // OK，数组大小为 120
  ```
  * 优势：`constexpr`函数让代码更灵活，支持复杂的编译时逻辑（如递归、循环等，`C++14`之后更强大）

#### 减少运行时错误
* `constexpr`的优势
  * 因为值在编译时确定，任何不符合常量表达式要求的代码都会在编译期报错，而不是运行时才暴露问题。这提高了代码的健壮性。
* 对比`const`
  * `const`的初始化可能依赖运行时数据，错误可能推迟到运行时发现。

---

## 从汇编角度理解
从汇编角度理解`int c = a + b`和`int c = a + 20`的区别

### 关键点：内存访问与指令的关系
* 内存访问：指的是从内存中读取数据的行为，通常通过加载指令（如`mov`）实现。
* 指令条数：指的是汇编代码中的独立指令行数。
* 在某些情况下，一条指令可以隐式完成内存访问，而无需额外的独立指令。这取决于操作数的寻址方式和指令的编码设计。

### 无优化情况（-O0）下的汇编对比
#### int c = a + b
```asm
mov eax, [a]    ; 将a的值加载到寄存器eax
add eax, [b]    ; 将b的值加到eax（隐式内存访问）
mov [c], eax    ; 将结果存储到c
```
* 指令数：`3`条。
* 内存访问：
  * `mov eax, [a]`：访问`a`的内存。
  * `add eax, [b]`：访问`b`的内存。
  * `mov [c], eax`：写入`c`的内存。
  * 总计：`2`次读内存（`a`和`b`），`1`次写内存。
#### int c = a + 20
```asm
mov eax, [a]    ; 将a的值加载到寄存器 eax
add eax, 20     ; 将立即数20加到eax（无内存访问）
mov [c], eax    ; 将结果存储到c
```
* 指令数：`3`条。
* 内存访问：
  * `mov eax, [a]`：访问`a`的内存。
  * `add eax, 20`：使用立即数，无内存访问。
  * `mov [c], eax`：写入`c`的内存。
  * 总计：`1`次读内存（`a`），`1` 次写内存。
#### 分析
* 指令数相同：两条语句都生成了`3`条指令。
* 内存访问差异：`a + b`多了一次内存访问（`[b]`），但这并没有增加指令条数。
* 原因：在 `add eax, [b]`中，内存访问是嵌入在`add`指令中的。`[b]`是一个内存操作数，直接作为加法的源操作数，而不是通过额外的`mov`指令加载到寄存器。

### 优化情况（-O2）下的对比
#### int c = a + b
```asm
add eax, ebx    ; 寄存器相加，无内存访问
mov [c], eax    ; 存储结果
```
* 指令数：`2`条。
* 内存访问：仅存储`c`时有`1`次写内存。
#### int c = a + 20
```asm
add eax, 20     ; 寄存器加立即数，无内存访问
mov [c], eax    ; 存储结果
```
* 指令数：`2`条。
* 内存访问：仅存储`c`时有`1`次写内存。
#### 分析
* 在优化情况下，`a`和`b`如果已在寄存器中，`a + b`和`a + 20`的内存访问次数相同（均为`0`次读），指令数也相同。
* 但如果`b`仍在内存中，`a + b`可能变成
  ```asm
  add eax, [b]    ; 内存访问嵌入在加法中
  mov [c], eax    ; 存储结果
  ```
  * 依然是`2`条指令，但多了一次内存访问。

### 性能影响
* 指令数相同，内存访问不同
  * `a + b`的`add eax, [b]`需要从内存读取`b`，这比`add eax, 20`（立即数操作）慢，因为内存访问的延迟（`1-100`周期，取决于缓存）远高于立即数操作（通常`1`周期）。
* 为什么不增加指令
  * `x86`架构允许单条指令直接操作内存操作数，`add`指令本身就能处理`[b]`的加载和计算，无需额外的`mov`。
  * 如果用`RISC`架构（如`ARM`），可能需要显式加载`b`到寄存器，多一条指令
* 性能差距
  * 多一次内存访问的代价是延迟（`1-100` 周期），而不是指令条数的增加。
  * 在无优化场景下，`a + b`比`a + 20`慢几纳秒（取决于缓存命中率）。
  * 在优化场景下，如果`b`在内存中，差距依然存在，但如果`b`在寄存器中，差距消失。

## epoll
在`Linux`系统中，`epoll`是一种高效的`I/O`事件通知机制，用于处理大量并发连接，特别是在服务器编程中。它解决了传统`select`和`poll`在高并发场景下的性能瓶颈问题。

### 什么是 epoll
* 定义：`epoll`是`Linux`内核提供的一种可扩展的`I/O`多路复用机制，适用于需要同时监控大量文件描述符（`fd`）的场景
* 优点：
  * 高效性：时间复杂度为`O(1)`，不像`select`和`poll`的`O(n)`。
  * 支持大量连接：可以处理数千甚至数十万的连接，而不会因`fd`数量增加导致性能急剧下降。
  * 事件驱动：只返回就绪的事件，避免遍历所有`fd`。
* 适用场景：网络服务器（如`Web`服务器、聊天服务器）处理高并发连接。

### 工作原理
* `epoll_create`：创建一个`epoll`实例，返回一个文件描述符（`epfd`）。
* `epoll_ctl`：向`epoll`实例注册或修改文件描述符及其感兴趣的事件（如可读、可写）。
* `epoll_wait`：等待事件发生，返回就绪的事件集合。
* 事件模型：
  * `LT`（`Level Triggered`，水平触发）：默认模式，只要 `fd` 状态未处理完，就会持续通知。
  * `ET`（`Edge Triggered`，边缘触发）：仅在 `fd` 状态变化时通知一次，要求一次性处理完数据，效率更高但编程复杂。

### 核心函数
#### epoll_create
```c++
int epoll_create(int size);
```
* 功能：创建一个 `epoll` 实例。
* 参数：
  * `size`：提示内核预期监控的`fd`数量（Linux 2.6.8 后仅为建议值，实际大小动态调整）。
* 返回值：
  * 成功：返回`epoll`文件描述符（`epfd`）。
  * 失败：返回`-1`，设置 `errno`。
* 注意：`C++11`后推荐用`epoll_create1(0)`（更现代的接口，支持`flags`，如`EPOLL_CLOEXEC`）

#### epoll_ctl
```c++
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
```
* 功能：控制`epoll`实例，添加、修改或删除监控的`fd`。
* 参数：
  * `epfd`：`epoll_create`返回的`epoll`文件描述符。
  * `op`：操作类型：
    * `EPOLL_CTL_ADD`：添加`fd`。
    * `EPOLL_CTL_MOD`：修改`fd`的事件。
    * `EPOLL_CTL_DEL`：删除`fd`。
  * `fd`：要监控的文件描述符（如`socket`）。
  * `event`：指向`struct epoll_event`的指针，定义事件类型。
* 事件结构
  ```c++
  struct epoll_event {
      uint32_t events;   // 事件类型（如 EPOLLIN EPOLLOUT）
      epoll_data_t data; // 用户数据
  };
  typedef union epoll_data {
      void *ptr;
      int fd;
      uint32_t u32;
      uint64_t u64;
  } epoll_data_t; 
  ```
  * 常见事件：
    * `EPOLLIN`：`fd`可读。
    * `EPOLLOUT`：`fd`可写。
    * `EPOLLERR`：`fd`发生错误。
    * `EPOLLET`：启用边缘触发模式。
* 返回值：
  * 成功：`0`。
  * 失败：`-1`，设置`errno`。

#### epoll_wait
```c++
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```
* 功能：等待事件发生，返回就绪的`fd`列表。
* 参数：
  * `epfd`：`epoll`实例的`fd`。
  * `events`：用户提供的数组，用于存储就绪事件。
  * `maxevents`：数组的最大容量。
  * `timeout`：超时时间（毫秒）：
    * `-1`：阻塞直到事件发生。
    * `0`：立即返回。
* 返回值：
  * 成功：返回就绪的事件数（`0`表示超时）。
  * 失败：`-1`，设置`errno`。

### 使用步骤
* 调用`epoll_create`创建`epoll`实例。
* 使用`epoll_ctl`注册需要监控的`fd`和事件。
* 在循环中调用`epoll_wait`等待事件。
* 处理返回的就绪事件。
* 使用完后关闭`epfd`和相关`fd`。

---

## _mm_pause()
`_mm_pause()`的主要目的是优化忙等待（`busy-waiting`）场景下的性能和功耗。它是`Intel`提供的`intrinsics`函数，定义在`<emmintrin.h>`中，
属于`SSE2`指令集，对应的汇编指令是`PAUSE`。

### 作用
`_mm_pause()` 是一个`CPU`指令，它告诉处理器当前线程正在执行一个短暂的暂停操作。

* 减少`CPU`资源争用
  * 在多线程程序中，当一个线程在忙等待（例如自旋锁或无锁队列的等待）时，它会持续占用`CPU`执行空循环（如`while (condition) {}`），这会导致高功耗和与其他线程争抢资源。
  * `PAUSE`指令让`CPU`在短时间内“休息”，减少这种争用。
* 降低功耗
  * 在空循环中不停执行指令会让`CPU`处于高负载状态，增加功耗。
  * `PAUSE`插入一个短暂的延迟（通常是几十到几百个时钟周期，具体取决于`CPU`架构），让 `CPU`有机会进入低功耗状态。
* 提高超线程效率
  * 在支持超线程（`Hyper-Threading`）的`CPU`上，同一个物理核心可能运行多个逻辑线程。如果一个线程在忙等待，它会占用核心的执行资源，影响另一个线程的性能。
  * `PAUSE`指令提示`CPU`暂停当前线程的执行单元，让其他超线程有更多机会运行。
* 避免内存顺序冲突
  * 在某些情况下，忙等待涉及检查共享变量（如`std::atomic`），可能会触发内存顺序推测（`memory order speculation`）的开销。`PAUSE`帮助缓解这种问题。

### 使用场景
```c++
while (!buffer.push(msg)) {
    _mm_pause(); // CPU暂停，避免忙等待浪费资源
}
```
* 为什么用在这里
  * 如果缓冲区满（生产者）或空（消费者），线程会进入一个短暂的等待状态。
  * 不用`_mm_pause()`，线程会一直执行紧凑的循环，浪费`CPU`周期并增加延迟。
  * 使用`_mm_pause()`，线程在每次循环中暂停一下，既降低了`CPU`使用率，又给了其他线程（如生产者或消费者）处理的机会。
* 效果
  * 减少了`CPU`的忙碌程度。
  * 在高竞争场景下（多线程访问缓冲区），提高了整体系统吞吐量。

### 底层实现
* 汇编指令：`_mm_pause()`直接翻译成`PAUSE`指令。
* 延迟时间
  * 在早期的`Intel CPU`（如 `Pentium 4`）上，`PAUSE`的延迟较长（约`100-200`周期）。
  * 在现代`CPU`（如`Skylake`或`newer`）上，延迟更短（约`10-140`周期），具体取决于型号和频率。
* 无副作用：它不改变任何寄存器或内存状态，只是影响`CPU`的执行流水线。

### 替代方案对比
如果不使用`_mm_pause()`，可能的替代方法包括：
* `std::this_thread::yield()`
  * 让出`CPU`执行权给其他线程，但会触发上下文切换，开销比`PAUSE`大得多（微秒级vs.纳秒级）。
* `std::this_thread::sleep_for()`
  * 睡眠一段时间（如`1`微秒），但延迟太长，不适合低延迟场景。
* 空循环
  * 不做任何优化，浪费`CPU`资源。

### 线程切换和上下文切换
* 线程切换：操作系统调度器决定暂停当前线程，切换到另一个线程运行。
* 上下文切换：保存当前线程的寄存器状态（如程序计数器、栈指针等），加载另一个线程的状态，通常伴随着线程切换。
* 这些操作需要：
  * 操作系统的干预（内核态切换）。
  * 保存和恢复上下文（几十到几百个周期的开销）。
  * 可能的缓存失效和`TLB`重载（额外延迟）。

### 为什么`_mm_pause()`不触发切换
* 无操作系统参与：
  * `_mm_pause()`是用户态的`CPU`指令，直接由硬件执行，不需要调用内核或调度器。
  * 它不会通知操作系统“当前线程需要让出`CPU`”，因此不会触发线程调度。
* 不改变线程状态：
  * 执行`PAUSE`时，当前线程仍然处于运行状态（`running state`），只是暂时停顿了一下。
  * 线程的上下文（寄存器、栈等）保持不变，暂停结束后立即继续执行下一条指令。
* 时间极短：
  * 暂停时间通常在纳秒级（例如，在`3GHz CPU`上，100周期≈33纳秒），远低于操作系统调度的时间粒度（微秒到毫秒级）。
  * 这么短的时间不足以触发调度器介入。

### 与`yield`/`sleep`的对比
* `std::this_thread::yield()`
  * 显式告诉操作系统“当前线程可以让出`CPU`”。
  * 调度器可能会切换到其他线程，导致上下文切换（开销 ≈ 微秒级）。
* `std::this_thread::sleep_for()`
  * 将线程置于睡眠状态，明确移除出运行队列。
  * 必然触发上下文切换（开销 ≈ 微秒到毫秒级）。
* `_mm_pause()`
  * 只暂停当前线程的流水线，不影响调度。
  * 无上下文切换，开销仅为几十到几百个 `CPU` 周期（纳秒级）。

### 硬件视角
* 在支持超线程（`Hyper-Threading`）的`CPU`上，`PAUSE`的作用更明显：
  * 一个物理核心可能同时运行两个逻辑线程。
  * 如果一个线程在忙等待（无`PAUSE`），它会持续占用执行单元，影响另一个线程。
  * 执行`PAUSE`时，`CPU`会短暂释放部分执行资源（如`ALU`或取指单元），让另一个超线程有更多机会运行，但这是在硬件层面完成的，不涉及操作系统切换。

### 总结
`_mm_pause()`不会导致线程切换或上下文切换，因为：
* 它是硬件指令，不涉及操作系统。
* 它只暂停当前线程的执行流水线，不改变线程状态。
* 暂停时间极短，远低于调度开销。

---

## 线程切换
### 主动让出CPU
线程通过调用特定的函数或指令，主动放弃当前的执行权，允许调度器切换到其他线程。
* `std::this_thread::yield()`
  * 作用：告诉操作系统当前线程愿意让出`CPU`，但不进入阻塞状态。
  * 场景：在忙等待时，避免线程长时间占用`CPU`。
  * 例子：
    ```c++
    while (!some_condition) {
      std::this_thread::yield(); // 让出CPU给其他线程
    }
    ```
  * 结果：调度器可能切换到另一个就绪线程，导致上下文切换。
* `std::this_thread::sleep_for()`或`sleep()`
  * 作用：将当前线程置于睡眠状态一段时间，移除出运行队列。
  * 场景：等待外部事件（如 I/O 或定时器）时。
    ```c++
    std::this_thread::sleep_for(std::chrono::milliseconds(10)); // 睡眠10ms
    ```
  * 结果：线程被挂起，必然触发上下文切换。
* `pthread_yield()`（`POSIX`系统）：
  * 作用：类似于 `std::this_thread::yield()`，显式让出`CPU`。
  * 场景：在`POSIX`系统中优化线程调度。

### 线程阻塞
当线程执行的操作需要等待资源或事件时，会被操作系统挂起，触发上下文切换。
* 等待锁（如`std::mutex`）：
  * 作用：如果锁被其他线程持有，当前线程阻塞。
  * 场景：多线程同步访问共享资源。
  * 例子：
    ```c++
    std::mutex mtx;
    std::lock_guard<std::mutex> lock(mtx); // 如果锁不可用，阻塞
    ```
  * 结果：线程进入等待状态，调度器切换到其他线程。
* 条件变量等待（如`std::condition_variable`）：
  * 作用：线程等待某个条件满足。
  * 场景：生产者-消费者模型。
  * 例子：
    ```c++
    std::condition_variable cv;
    std::mutex mtx;
    std::unique_lock<std::mutex> lock(mtx);
    cv.wait(lock); // 等待信号
    ```
  * 结果：线程阻塞，上下文切换发生。
* `I/O`操作：
  * 作用：等待文件、网络或设备输入/输出。
  * 场景：读取文件、接收网络数据。
  * 例子：
    ```c++
    char buffer[1024];
    read(fd, buffer, sizeof(buffer)); // 如果数据未就绪，阻塞
    ```
  * 结果：线程进入等待`I/O`状态，调度器切换线程。

### 时间片耗尽
操作系统调度器基于时间片（`time slice`）分配`CPU`时间，当当前线程的时间片用尽时，会被抢占。
* 抢占式调度：
  * 作用：操作系统中断当前线程，切换到另一个就绪线程。
  * 场景：多任务系统中，确保公平性。
  * 触发条件：
    * 线程运行时间超过分配的时间片（通常几毫秒，取决于调度策略，如`Linux CFS`）。
    * 高优先级线程就绪。
  * 例子：
    ```c++
    while (true) {
      // 长时间计算，可能被抢占
    }
    ```
  * 结果：线程被暂停，上下文切换到其他线程。

### 外部中断
硬件中断或信号会导致线程被暂停，操作系统可能切换到其他线程。

* 硬件中断：
  * 作用：`CPU`响应外部事件（如定时器、网络数据到达）。
  * 场景：定时器中断触发调度。
  * 结果：当前线程被中断，如果调度器决定切换线程，则发生上下文切换。
* 信号处理（如`SIGINT`）：
  * 作用：线程接收信号并进入信号处理程序。
  * 场景：用户按`Ctrl+C`终止程序。
  * 例子：
    ```c++
    signal(SIGINT, handler); // 注册信号处理
    ```
  * 结果：线程可能被暂停，切换到其他线程。

### 线程同步原语
某些同步操作可能隐式导致线程让出`CPU`。
* 等待信号量（如`sem_wait`）：
  * 作用：如果信号量不可用，线程阻塞。
  * 例子：
    ```c++
    sem_t sem;
    sem_wait(&sem); // 等待信号量
    ```
  * 结果：线程挂起，上下文切换。
* `futex`（`Linux`）：
  * 作用：低级同步原语，等待时阻塞。
  * 场景：`std::mutex`底层可能基于`futex`实现。

### 系统调用
某些系统调用可能导致线程进入内核态并阻塞。
* 例子：
  * `waitpid()`：等待子进程结束。
  * `select()`或`poll()`：等待文件描述符就绪。
* 结果：线程阻塞，触发上下文切换。

### 特殊情况
* 线程结束：
  * 调用`pthread_exit()`或从线程函数返回，线程终止，切换到其他线程。
* `CPU`核心不足：
  * 如果运行的线程数超过`CPU`核心数，调度器会频繁切换线程。

### 总结
会导致线程让出并触发上下文切换的情况包括：
* 主动让出（如`yield`、`sleep`）。
* 阻塞操作（如锁、`I/O`、条件变量）。
* 时间片耗尽（抢占）。
* 外部中断或信号。
* 系统调用或线程终止。










